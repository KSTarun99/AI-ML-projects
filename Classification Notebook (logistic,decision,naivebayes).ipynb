{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "473f227e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider there is submarine, submarine is going underwater, submarine has to predict object beneath is rock or mine, \n",
    "#so it uses sonar signal to check wheather it is rock or mine.\n",
    "#mines are made up of metals, once we feed sonar data to ml model,it will predict it as rock or metal.\n",
    "\n",
    "#import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9923242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_rock_mine = pd.read_csv(\"C:\\\\Users\\\\welcome\\\\Downloads\\\\Copy of sonar data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2be274",
   "metadata": {},
   "source": [
    "**work flow**<br>\n",
    "1. data collection.<br>\n",
    "2. preprocess data.<br>\n",
    "3. split your data into training data and testing data ( train test split), here we will train our model with training data and    evaluate our model with test data.<br>\n",
    "4. now, we can feed this to logistic regression model(ML Model)<br>(logistic works well for binary classification)(supervised)\n",
    "    (rock or mine) prediction.(binary classification)\n",
    "5. here we are predicting one particular value. this is a regression problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349f5fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 61)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of rows and coloumns\n",
    "s_rock_mine.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f245fb8e",
   "metadata": {},
   "source": [
    "Data collection and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8ac3446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "      <th>R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0317</td>\n",
       "      <td>0.0956</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.1674</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.1401</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1027</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0647</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0697</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "5  0.0317  0.0956  0.1321  0.1408  0.1674  0.1710  0.0731  0.1401  0.2083   \n",
       "6  0.0519  0.0548  0.0842  0.0319  0.1158  0.0922  0.1027  0.0613  0.1465   \n",
       "7  0.0223  0.0375  0.0484  0.0475  0.0647  0.0591  0.0753  0.0098  0.0684   \n",
       "8  0.0164  0.0173  0.0347  0.0070  0.0187  0.0671  0.1056  0.0697  0.0962   \n",
       "9  0.0039  0.0063  0.0152  0.0336  0.0310  0.0284  0.0396  0.0272  0.0323   \n",
       "\n",
       "   0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084  \\\n",
       "0  0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "1  0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "2  0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "3  0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "4  0.3039  ...  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057  0.0027   \n",
       "5  0.3513  ...  0.0201  0.0248  0.0131  0.0070  0.0138  0.0092  0.0143   \n",
       "6  0.2838  ...  0.0081  0.0120  0.0045  0.0121  0.0097  0.0085  0.0047   \n",
       "7  0.1487  ...  0.0145  0.0128  0.0145  0.0058  0.0049  0.0065  0.0093   \n",
       "8  0.0251  ...  0.0090  0.0223  0.0179  0.0084  0.0068  0.0032  0.0035   \n",
       "9  0.0452  ...  0.0062  0.0120  0.0052  0.0056  0.0093  0.0042  0.0003   \n",
       "\n",
       "   0.0090  0.0032  R  \n",
       "0  0.0052  0.0044  R  \n",
       "1  0.0095  0.0078  R  \n",
       "2  0.0040  0.0117  R  \n",
       "3  0.0107  0.0094  R  \n",
       "4  0.0051  0.0062  R  \n",
       "5  0.0036  0.0103  R  \n",
       "6  0.0048  0.0053  R  \n",
       "7  0.0059  0.0022  R  \n",
       "8  0.0056  0.0040  R  \n",
       "9  0.0053  0.0036  R  \n",
       "\n",
       "[10 rows x 61 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rock_mine.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f78047f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "#used for calculating accuracy score of our model, thereby we can conclude which model is the best for our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e54d22fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "      <td>207.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.029208</td>\n",
       "      <td>0.038443</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>0.054053</td>\n",
       "      <td>0.075105</td>\n",
       "      <td>0.104599</td>\n",
       "      <td>0.121591</td>\n",
       "      <td>0.134677</td>\n",
       "      <td>0.177361</td>\n",
       "      <td>0.208245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016034</td>\n",
       "      <td>0.013472</td>\n",
       "      <td>0.010729</td>\n",
       "      <td>0.010917</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.007771</td>\n",
       "      <td>0.007947</td>\n",
       "      <td>0.007936</td>\n",
       "      <td>0.006523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.023038</td>\n",
       "      <td>0.033040</td>\n",
       "      <td>0.038521</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.055669</td>\n",
       "      <td>0.059247</td>\n",
       "      <td>0.061897</td>\n",
       "      <td>0.085340</td>\n",
       "      <td>0.118311</td>\n",
       "      <td>0.134741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012027</td>\n",
       "      <td>0.009628</td>\n",
       "      <td>0.007071</td>\n",
       "      <td>0.007310</td>\n",
       "      <td>0.007103</td>\n",
       "      <td>0.005719</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.006485</td>\n",
       "      <td>0.006196</td>\n",
       "      <td>0.005038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.010200</td>\n",
       "      <td>0.003300</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.016400</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.024450</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.066950</td>\n",
       "      <td>0.080600</td>\n",
       "      <td>0.080350</td>\n",
       "      <td>0.096750</td>\n",
       "      <td>0.111150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008350</td>\n",
       "      <td>0.007350</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.005350</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.003100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.044100</td>\n",
       "      <td>0.062000</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.105600</td>\n",
       "      <td>0.111900</td>\n",
       "      <td>0.152200</td>\n",
       "      <td>0.181000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013800</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.009600</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.005300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.065700</td>\n",
       "      <td>0.101050</td>\n",
       "      <td>0.134150</td>\n",
       "      <td>0.153050</td>\n",
       "      <td>0.169800</td>\n",
       "      <td>0.231500</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.016750</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.014450</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.010350</td>\n",
       "      <td>0.008550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.137100</td>\n",
       "      <td>0.233900</td>\n",
       "      <td>0.305900</td>\n",
       "      <td>0.426400</td>\n",
       "      <td>0.401000</td>\n",
       "      <td>0.382300</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.459000</td>\n",
       "      <td>0.682800</td>\n",
       "      <td>0.710600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.070900</td>\n",
       "      <td>0.039000</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.036400</td>\n",
       "      <td>0.043900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0.0200      0.0371      0.0428      0.0207      0.0954      0.0986  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.029208    0.038443    0.043837    0.054053    0.075105    0.104599   \n",
       "std      0.023038    0.033040    0.038521    0.046583    0.055669    0.059247   \n",
       "min      0.001500    0.000600    0.001500    0.005800    0.006700    0.010200   \n",
       "25%      0.013300    0.016400    0.018900    0.024450    0.037700    0.066950   \n",
       "50%      0.022800    0.030800    0.034200    0.044100    0.062000    0.092100   \n",
       "75%      0.035800    0.048100    0.058200    0.065700    0.101050    0.134150   \n",
       "max      0.137100    0.233900    0.305900    0.426400    0.401000    0.382300   \n",
       "\n",
       "           0.1539      0.1601      0.3109      0.2111  ...      0.0232  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  ...  207.000000   \n",
       "mean     0.121591    0.134677    0.177361    0.208245  ...    0.016034   \n",
       "std      0.061897    0.085340    0.118311    0.134741  ...    0.012027   \n",
       "min      0.003300    0.005500    0.007500    0.011300  ...    0.000000   \n",
       "25%      0.080600    0.080350    0.096750    0.111150  ...    0.008350   \n",
       "50%      0.105600    0.111900    0.152200    0.181000  ...    0.013800   \n",
       "75%      0.153050    0.169800    0.231500    0.269000  ...    0.020700   \n",
       "max      0.372900    0.459000    0.682800    0.710600  ...    0.100400   \n",
       "\n",
       "           0.0027      0.0065      0.0159      0.0072      0.0167      0.0180  \\\n",
       "count  207.000000  207.000000  207.000000  207.000000  207.000000  207.000000   \n",
       "mean     0.013472    0.010729    0.010917    0.009300    0.008181    0.007771   \n",
       "std      0.009628    0.007071    0.007310    0.007103    0.005719    0.005756   \n",
       "min      0.000800    0.000500    0.001000    0.000600    0.000400    0.000300   \n",
       "25%      0.007350    0.005050    0.005350    0.004100    0.004400    0.003700   \n",
       "50%      0.011500    0.009600    0.009300    0.007500    0.006800    0.005900   \n",
       "75%      0.016750    0.014900    0.014450    0.012100    0.010350    0.010350   \n",
       "max      0.070900    0.039000    0.035200    0.044700    0.039400    0.035500   \n",
       "\n",
       "           0.0084      0.0090      0.0032  \n",
       "count  207.000000  207.000000  207.000000  \n",
       "mean     0.007947    0.007936    0.006523  \n",
       "std      0.006485    0.006196    0.005038  \n",
       "min      0.000300    0.000100    0.000600  \n",
       "25%      0.003600    0.003650    0.003100  \n",
       "50%      0.005800    0.006300    0.005300  \n",
       "75%      0.010400    0.010350    0.008550  \n",
       "max      0.044000    0.036400    0.043900  \n",
       "\n",
       "[8 rows x 60 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rock_mine.describe()\n",
    "#statistical definitions for this data (mean, std, other parameters for this data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "588323bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     96\n",
       "Name: R, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_rock_mine.R.value_counts()\n",
    "#more the data then more the accurate it is...\n",
    "#M- Mine\n",
    "#R- Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35e82fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Seperating data and labels\n",
    "#supervised- we use labels (rock and mine)\n",
    "X = s_rock_mine.drop('R', axis = 1)\n",
    "Y = s_rock_mine.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6832c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets use train test split function to split our data, so we need to give our variable names.\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.1, stratify =Y, random_state =1)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4c5cbc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60) (165, 60) (165,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, X_train.shape, Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0f8a44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
      "73   0.0109  0.0093  0.0121  0.0378  0.0679  0.0863  0.1004  0.0664  0.0941   \n",
      "166  0.0137  0.0297  0.0116  0.0082  0.0241  0.0253  0.0279  0.0130  0.0489   \n",
      "138  0.0164  0.0627  0.0738  0.0608  0.0233  0.1048  0.1338  0.0644  0.1522   \n",
      "199  0.0131  0.0387  0.0329  0.0078  0.0721  0.1341  0.1626  0.1902  0.2610   \n",
      "84   0.0365  0.1632  0.1636  0.1421  0.1130  0.1306  0.2112  0.2268  0.2992   \n",
      "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "133  0.1083  0.1070  0.0257  0.0837  0.0748  0.1125  0.3322  0.4590  0.5526   \n",
      "137  0.0731  0.1249  0.1665  0.1496  0.1443  0.2770  0.2555  0.1712  0.0466   \n",
      "72   0.0139  0.0222  0.0089  0.0108  0.0215  0.0136  0.0659  0.0954  0.0786   \n",
      "140  0.0707  0.1252  0.1447  0.1644  0.1693  0.0844  0.0715  0.0947  0.1583   \n",
      "37   0.0123  0.0022  0.0196  0.0206  0.0180  0.0492  0.0033  0.0398  0.0791   \n",
      "\n",
      "     0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  \\\n",
      "73   0.1036  ...  0.0124  0.0077  0.0023  0.0117  0.0053  0.0077  0.0076   \n",
      "166  0.0874  ...  0.0169  0.0081  0.0040  0.0025  0.0036  0.0058  0.0067   \n",
      "138  0.0780  ...  0.0244  0.0258  0.0143  0.0226  0.0187  0.0185  0.0110   \n",
      "199  0.3193  ...  0.0137  0.0150  0.0076  0.0032  0.0037  0.0071  0.0040   \n",
      "84   0.3735  ...  0.0223  0.0110  0.0071  0.0205  0.0164  0.0063  0.0078   \n",
      "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "133  0.5966  ...  0.0172  0.0180  0.0110  0.0234  0.0276  0.0032  0.0084   \n",
      "137  0.1114  ...  0.0361  0.0444  0.0230  0.0290  0.0141  0.0161  0.0177   \n",
      "72   0.1015  ...  0.0024  0.0062  0.0072  0.0113  0.0012  0.0022  0.0025   \n",
      "140  0.1247  ...  0.0291  0.0156  0.0197  0.0135  0.0127  0.0138  0.0133   \n",
      "37   0.0475  ...  0.0149  0.0125  0.0134  0.0026  0.0038  0.0018  0.0113   \n",
      "\n",
      "     0.0084  0.0090  0.0032  \n",
      "73   0.0056  0.0055  0.0039  \n",
      "166  0.0035  0.0043  0.0033  \n",
      "138  0.0094  0.0078  0.0112  \n",
      "199  0.0009  0.0015  0.0085  \n",
      "84   0.0094  0.0110  0.0068  \n",
      "..      ...     ...     ...  \n",
      "133  0.0122  0.0082  0.0143  \n",
      "137  0.0194  0.0207  0.0057  \n",
      "72   0.0059  0.0039  0.0048  \n",
      "140  0.0131  0.0154  0.0218  \n",
      "37   0.0058  0.0047  0.0071  \n",
      "\n",
      "[165 rows x 60 columns]\n",
      "73     R\n",
      "166    M\n",
      "138    M\n",
      "199    M\n",
      "84     R\n",
      "      ..\n",
      "133    M\n",
      "137    M\n",
      "72     R\n",
      "140    M\n",
      "37     R\n",
      "Name: R, Length: 165, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fdd43ac",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "After importing the class, we will create a classifier object and use it to fit the model to the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fad9a251",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MODEL iS Logistic regression \n",
    "#load your model into a variable\n",
    "model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca319dc",
   "metadata": {},
   "source": [
    "Logistic regression is one of the most popular Machine Learning algorithms,<br> which comes under the Supervised Learning technique.<br> Therefore the outcome must be a categorical or discrete value. It can be either Yes or No, 0 or 1, true or False, etc.<br>Logistic regression is used for solving the classification problems.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8639ba",
   "metadata": {},
   "source": [
    "Fitting Logistic Regression to the Training set:<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5576cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train your model with train data\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2a6577",
   "metadata": {},
   "source": [
    "Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a50c04",
   "metadata": {},
   "source": [
    "In Logistic regression, instead of fitting a regression line, we fit an \"S\" shaped logistic function, which predicts two maximum values<br>\n",
    "The curve from the logistic function indicates the likelihood of something such as beneath the submarine are mine or not<br>\n",
    "Logistic Regression is a significant machine learning algorithm because it has the ability to provide probabilities and classify new data using continuous and discrete datasets.<br>\n",
    "Logistic Regression can be used to classify the observations using different types of data and can easily determine the most effective variables used for the classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "354d41ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK ACCURACY score on training data\n",
    "#use same data, that ml model have learnt..\n",
    "#model have seen training data but havent seen test data..accuracy will be  more for training data\n",
    "#check accuracy on both training and testing data.. any accuracy greater than 70per is good,if we use better model.\n",
    "#lets predict training data\n",
    "x_train_prediction = model.predict(X_train)\n",
    "training_data_accuracy = accuracy_score(x_train_prediction,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "66efb665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for training data 0.8303030303030303\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy for training data\", training_data_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9dbc0499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CHECK ACCURACY score on test data\n",
    "x_test_prediction = model.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(x_test_prediction,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c05a1189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test data 0.8095238095238095\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy on test data\" , test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5dbb4fb",
   "metadata": {},
   "source": [
    "Logistic Function (Sigmoid Function):<br>\n",
    "The sigmoid function is a mathematical function used to map the predicted values to probabilities.<br>\n",
    "It maps any real value into another value within a range of 0 and 1.<br>\n",
    "The value of the logistic regression must be between 0 and 1, which cannot go beyond this limit, so it forms a curve like the \"S\" form. The S-form curve is called the Sigmoid function or the logistic function.<br>\n",
    "In logistic regression, we use the concept of the threshold value, which defines the probability of either 0 or 1. Such as values above the threshold value tends to 1, and a value below the threshold values tends to 0.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1be2c42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The object here is ['M']\n",
      "prediction is a MINE\n"
     ]
    }
   ],
   "source": [
    "#i have taken some randomn value to check my model prdction\n",
    "predictive_system_data = (0.0261,0.0266,0.0223,0.0749,0.1364,0.1513,0.1316,0.1654,0.1864,0.2013,0.2890,0.3650,0.3510,0.3495,0.4325,0.5398,0.6237,0.6876,0.7329,0.8107,0.8396,0.8632,0.8747,0.9607,0.9716,0.9121,0.8576,0.8798,0.7720,0.5711,0.4264,0.2860,0.3114,0.2066,0.1165,0.0185,0.1302,0.2480,0.1637,0.1103,0.2144,0.2033,0.1887,0.1370,0.1376,0.0307,0.0373,0.0606,0.0399,0.0169,0.0135,0.0222,0.0175,0.0127,0.0022,0.0124,0.0054,0.0021,0.0028,0.0023)\n",
    "# here it in tupple data type, so change it to numpy array\n",
    "# changing input_data to a numpy array, becoz it is easy to do some processing on arrays rather than tupple..\n",
    "data_input_as_numpy_array = np.asarray(predictive_system_data)\n",
    "#here we are predicting for one instance only.\n",
    "# reshape the array,if we dont mention reshape here, the model doesnt know that we are predicting one data point particularly.\n",
    "data_reshaped2 = data_input_as_numpy_array.reshape(1,-1)\n",
    "#prediction will give me the selling price for ertiga..\n",
    "prediction2 =  model.predict(data_reshaped2)\n",
    "\n",
    "\n",
    "print('The object here is', prediction2)\n",
    "\n",
    "\n",
    "if(prediction2 =='R'):\n",
    "    print ('prediction is a ROCK here')\n",
    "else:\n",
    "    print('prediction is a MINE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa3c538",
   "metadata": {},
   "source": [
    "since the sigmoid curve has all the properties you would want — extremely low values in the start, <br>\n",
    "extremely high values in the end, and intermediate values in the middle — it’s a good choice for modelling the value of the probability of rock vs mine."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04eacc6f",
   "metadata": {},
   "source": [
    "Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "0a51d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1 = s_rock_mine.drop(\"R\", axis = 1)\n",
    "Y_1 = s_rock_mine.R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "651dd74e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    R\n",
       "1    R\n",
       "2    R\n",
       "3    R\n",
       "4    R\n",
       "Name: R, dtype: object"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1122dd3c",
   "metadata": {},
   "source": [
    "splitting training data and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "763fc237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6e79990b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X_1,Y_1, train_size = 0.7, random_state = 42)\n",
    "#p.random.seed(0)\n",
    "#_train,s_test=train_test_split(s_rock_mine, train_size=0.7, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "14d77ef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((207, 60), (144, 60), (144,), (63, 60))"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape, X_train.shape, Y_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "2c15eb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.0200</th>\n",
       "      <th>0.0371</th>\n",
       "      <th>0.0428</th>\n",
       "      <th>0.0207</th>\n",
       "      <th>0.0954</th>\n",
       "      <th>0.0986</th>\n",
       "      <th>0.1539</th>\n",
       "      <th>0.1601</th>\n",
       "      <th>0.3109</th>\n",
       "      <th>0.2111</th>\n",
       "      <th>...</th>\n",
       "      <th>0.0232</th>\n",
       "      <th>0.0027</th>\n",
       "      <th>0.0065</th>\n",
       "      <th>0.0159</th>\n",
       "      <th>0.0072</th>\n",
       "      <th>0.0167</th>\n",
       "      <th>0.0180</th>\n",
       "      <th>0.0084</th>\n",
       "      <th>0.0090</th>\n",
       "      <th>0.0032</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0277</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1201</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.3039</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0038</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109  \\\n",
       "0  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "1  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "2  0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "3  0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "4  0.0286  0.0453  0.0277  0.0174  0.0384  0.0990  0.1201  0.1833  0.2105   \n",
       "\n",
       "   0.2111  ...  0.0232  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  \\\n",
       "0  0.2872  ...  0.0125  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140   \n",
       "1  0.6194  ...  0.0033  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316   \n",
       "2  0.1264  ...  0.0241  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050   \n",
       "3  0.4459  ...  0.0156  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072   \n",
       "4  0.3039  ...  0.0104  0.0045  0.0014  0.0038  0.0013  0.0089  0.0057   \n",
       "\n",
       "   0.0084  0.0090  0.0032  \n",
       "0  0.0049  0.0052  0.0044  \n",
       "1  0.0164  0.0095  0.0078  \n",
       "2  0.0044  0.0040  0.0117  \n",
       "3  0.0048  0.0107  0.0094  \n",
       "4  0.0027  0.0051  0.0062  \n",
       "\n",
       "[5 rows x 60 columns]"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c2ecd",
   "metadata": {},
   "source": [
    "#### Fit the Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "433ca844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "56892591",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_x= StandardScaler()  \n",
    "x_train= st_x.fit_transform(X_train)    \n",
    "x_test= st_x.transform(X_test)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "9d1e3c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b52db05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier= DecisionTreeClassifier(criterion='entropy', random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "51d6fb8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048fbbd",
   "metadata": {},
   "source": [
    "In the above code, we have created a classifier object, in which we have passed two main parameters;\n",
    "\n",
    "criterion='entropy': Criterion is used to measure the quality of split, which is calculated by information gain given by entropy.<br>\n",
    "random_state=0: For generating the random states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "99e2d575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we will predict the train set result. We will create a new prediction vector x_pred. Below is the code for it:\n",
    "#Predicting the train set result  \n",
    "x_pred= classifier.predict(X_train)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "f43f8fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_train, x_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "567c6fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred= classifier.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "9d36f81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(Y_test, test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d34e84",
   "metadata": {},
   "source": [
    "Naive bayes<br>\n",
    "Data Pre-processing step<br>\n",
    "Fitting Naive Bayes to the Training set<br>\n",
    "Predicting the test result<br>\n",
    "Test accuracy of the result<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fb95f97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test = train_test_split(X_1,Y_1, test_size = 0.25, random_state = 0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "cd2e7035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling  \n",
    "from sklearn.preprocessing import StandardScaler  \n",
    "sc = StandardScaler()  \n",
    "x_train = sc.fit_transform(x_train)  \n",
    "x_test = sc.transform(x_test)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcacf31",
   "metadata": {},
   "source": [
    "Fitting Naive Bayes to the Training Set:<br>\n",
    "After the pre-processing step, now we will fit the Naive Bayes model to the Training set\n",
    "Gaussian: <br>The Gaussian model assumes that features follow a normal distribution. <br>This means if predictors take continuous values instead of discrete, <br> then the model assumes that these values are sampled from the Gaussian distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "a5ddbb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "classifier = GaussianNB()  \n",
    "classifier.fit(x_train, y_train)  \n",
    "#GaussianNB classifier to fit it to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "7bc6b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction of the test set result:\n",
    "#Now we will predict the test set result. For this, \n",
    "#we will create a new predictor variable y_pred, and will use the predict function to make the predictions.\n",
    "# Predicting the Test set results  \n",
    "y_pred = classifier.predict(x_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6691c69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6538461538461539\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test,y_pred ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a71943",
   "metadata": {},
   "source": [
    "Advantages of Naïve Bayes Classifier:<br>\n",
    "Naïve Bayes is one of the fast and easy ML algorithms to predict a class of datasets.<br>\n",
    "It can be used for Binary as well as Multi-class Classifications.<br>\n",
    "It performs well in Multi-class predictions as compared to the other Algorithms.<br>\n",
    "It is the most popular choice for text classification problems.<br>\n",
    "Disadvantages of Naïve Bayes Classifier:<br>\n",
    "Naive Bayes assumes that all features are independent or unrelated, so it cannot learn the relationship between features.<br>\n",
    "Applications of Naïve Bayes Classifier:<br>\n",
    "It is used for Credit Scoring.<br>\n",
    "It is used in medical data classification.<br>\n",
    "It can be used in real-time predictions because Naïve Bayes Classifier is an eager learner.<br>\n",
    "It is used in Text classification such as Spam filtering and Sentiment analysis.<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
